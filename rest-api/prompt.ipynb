{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f25a29-8ce0-40a3-8493-223f37ed5f9f",
   "metadata": {},
   "source": [
    "# Prompt API example\n",
    "\n",
    "This notebook demonstrates the use of the TrustGraph prompt API to invoke a prompt template.\n",
    "\n",
    "The prompt API can return either a text response or an object response, this example returns text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf1909b0-26a1-432a-9567-e0e053855c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1de842-f397-465c-907b-948396a29288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID of flow\n",
    "flow = \"default\"\n",
    "base_url = \"http://localhost:8088\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4155f32d-98fb-4f24-8905-a6f472064648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the TrustGraph prompt API\n",
    "url = f\"{base_url}/api/v1/flow/{flow}/service/prompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ced374-91a2-4ecd-98fe-3b7d65a444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prompt invocation consists of the identifier of the prompt template plus a set of variables in key/value form.\n",
    "# The prompt is not specified here, it is taken from templates\n",
    "input = {\n",
    "    \"id\": \"question\",\n",
    "    \"variables\": {\n",
    "        \"question\": \"Write a joke about llamas.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760d589a-0d00-46f7-b9eb-c127a6b3c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the API, input is passed as JSON\n",
    "resp = requests.post(url, json=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f81b83f-be3f-431d-b03d-29618f33b69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be a 200 status code\n",
    "resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9207ab-1ab8-43c5-82a4-1b5c0aacc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the response as JSON\n",
    "resp = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb879139-6955-4f76-8ee0-e9dad6efc56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the llama cross the road?\n",
      "\n",
      "To prove he wasn't chicken! He heard there was alpaca lunch on the other side.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The output of this prompt is just 'text' so access through the 'text' attribute\n",
    "print(resp[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a5ab8-0c04-4cff-a6de-3104ff2a3a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
